{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Familiarisation with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from MNIST_dataloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define parameters\n",
    "    data_loc = os.path.abspath(\".\") #change the datalocation to something that works for you\n",
    "    batch_size = 64\n",
    "    \n",
    "    # get dataloader\n",
    "    train_loader,val_loader, test_loader = create_dataloaders(data_loc, batch_size)\n",
    "    \n",
    "    # get some examples\n",
    "    examples = enumerate(test_loader)\n",
    "    _, (x_clean_example, x_noisy_example, labels_example) = next(examples)\n",
    "    # use these example images througout the assignment as the first 10 correspond to the digits 0-9\n",
    "    \n",
    "    # show the examples in a plot\n",
    "    plt.figure(figsize=(12,3))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2,10,i+1)\n",
    "        plt.imshow(x_clean_example[i,0,:,:],cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        plt.subplot(2,10,i+11)\n",
    "        plt.imshow(x_noisy_example[i,0,:,:],cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r\"figure\\data_examples.png\",dpi=300,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Interval for printing loss during training\n",
    "print_every = 100\n",
    "\n",
    "print(f'Using device:{device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Build up a fully connected network with linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerFC_o_act(nn.Module):\n",
    "    def __init__(self,in_neuron,hidden1_neuron,hidden2_neuron,out_neuron):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_neuron,hidden1_neuron)\n",
    "        self.fc2 = nn.Linear(hidden1_neuron,hidden2_neuron)\n",
    "        self.fc3 = nn.Linear(hidden2_neuron,out_neuron)\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def test_ThreeLayerFC():\n",
    "    x = torch.zeros((64,32,32)).view((64,32*32))\n",
    "    model = ThreeLayerFC_o_act(in_neuron=32*32,hidden1_neuron=64*64,hidden2_neuron=128*128,out_neuron=32*32)\n",
    "    result = model(x)\n",
    "    print(result.shape)\n",
    "\n",
    "test_ThreeLayerFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer, loss calculation and plot\n",
    "\n",
    "def flatten(x):\n",
    "    return x.view(len(x),-1)\n",
    "\n",
    "def loss_epoch(loss_ls,model,loader) -> list:\n",
    "    model.eval() # model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        loss_epoch=0\n",
    "        for t,(x_clean,x_noisy,_) in enumerate(loader):\n",
    "            x_noisy = x_noisy.to(device=device, dtype=torch.float32)\n",
    "            x_clean = x_clean.to(device=device, dtype=torch.float32)\n",
    "            out_x = model(flatten(x_noisy))\n",
    "            loss=F.mse_loss(out_x,flatten(x_clean))\n",
    "            loss_epoch += loss\n",
    "        loss_ls.append(loss_epoch/t)\n",
    "\n",
    "def loss_batch(loss_ls,model,loader) -> list:\n",
    "    model.eval() # model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for _,(x_clean,x_noisy,_) in enumerate(loader):\n",
    "            x_noisy = x_noisy.to(device=device, dtype=torch.float32)\n",
    "            x_clean = x_clean.to(device=device, dtype=torch.float32)\n",
    "            out_x = model(flatten(x_noisy))\n",
    "            loss=F.mse_loss(out_x,flatten(x_clean))\n",
    "        loss_ls.append(loss)   \n",
    "\n",
    "def trainer(model,optimizer, epochs=1):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    model = model.to(device=device)\n",
    "    for e in range(epochs):\n",
    "        for _,(x_clean,x_noisy,_) in enumerate(train_loader):\n",
    "            x_noisy = x_noisy.to(device=device, dtype=torch.float32)\n",
    "            x_clean = x_clean.to(device=device, dtype=torch.float32)\n",
    "            model.train() # training mode\n",
    "            out_x = model(flatten(x_noisy))\n",
    "            loss = F.mse_loss(out_x,flatten(x_clean))\n",
    "            optimizer.zero_grad() #reset gradients\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_epoch(loss_train,model,train_loader)\n",
    "        loss_epoch(loss_val,model,val_loader)\n",
    "        print(f'epoch {e+1}:train loss={loss_train[e]},val loss={loss_val[e]}')\n",
    "    return loss_train,loss_val\n",
    "\n",
    "def loss_plot(loss_train,loss_val,epoch,figname:str):\n",
    "    x = range(1,epoch+1)\n",
    "    plt.plot(x,loss_train,'r-',label=\"training loss\")\n",
    "    plt.plot(x,loss_val,'k:',label=\"validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss(MSE)\")\n",
    "    plt.title(\"Train/Val Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"figure/{figname}.png\")\n",
    "    plt.show()\n",
    "\n",
    "def prediction(model,x): #test\n",
    "    model = model.to(device=device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device=device,dtype=torch.float32)\n",
    "        out_x = torch.Tensor.cpu(model(flatten(x)))\n",
    "    return out_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_neuron=32*32\n",
    "hidden1_neuron=64*64\n",
    "hidden2_neuron=64*64\n",
    "out_neuron=32*32\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "model_o_act = ThreeLayerFC_o_act(in_neuron,hidden1_neuron,hidden2_neuron,out_neuron)\n",
    "optimizer = optim.SGD(model_o_act.parameters(),lr) #default momentum=0\n",
    "epoch=20\n",
    "\n",
    "train_loss,val_loss = trainer(model_o_act,optimizer,epoch)\n",
    "loss_plot(train_loss,val_loss,epoch,\"loss_o_act\")\n",
    "PATH = os.path.join(os.path.abspath(\".\"), \"model\")\n",
    "torch.save(model_o_act,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o_act_untrained = ThreeLayerFC_o_act(in_neuron,hidden1_neuron,hidden2_neuron,out_neuron)\n",
    "\n",
    "# get some examples\n",
    "examples = enumerate(test_loader)\n",
    "_, (x_clean_example, x_noisy_example, labels_example) = next(examples)\n",
    "\n",
    "# prediction\n",
    "x_untrained_example = prediction(model_o_act_untrained,x_noisy_example).reshape(64,1,32,32)\n",
    "x_trained_example = prediction(model_o_act,x_noisy_example).reshape(64,1,32,32)\n",
    "\n",
    "# comparison of trained/untrained examples with clean and noisy figures\n",
    "plt.figure(figsize=(40,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(4,10,i+1)\n",
    "    plt.imshow(x_clean_example[i,0,:,:],cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(4,10,i+11)\n",
    "    plt.imshow(x_noisy_example[i,0,:,:],cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4,10,i+21)\n",
    "    plt.imshow(x_untrained_example[i,0,:,:],cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4,10,i+31)\n",
    "    plt.imshow(x_trained_example[i,0,:,:],cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"figure/data_examples_o_act.png\",dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear layers with activation(ReLu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    y = torch.zeros_like(x)\n",
    "    return torch.where(x<=0,x,y)\n",
    "\n",
    "#test ReLu\n",
    "test_relu= torch.randn(3,2)\n",
    "print(test_relu)\n",
    "print(ReLu(test_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relu\n",
    "plot_relu_x = torch.arange(-100,100,1)\n",
    "plot_relu_y = ReLu(plot_relu_x)\n",
    "plt.plot(plot_relu_x,plot_relu_y,'r-',label=\"ReLu\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ReLU(x)\")\n",
    "plt.title(\"Output of ReLu function\")\n",
    "plt.legend()\n",
    "plt.savefig(r'figure/ReLu.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with ReLU activation\n",
    "class ThreeLayerFC_act(nn.Module):\n",
    "    def __init__(self,in_neuron,hidden1_neuron,hidden2_neuron,out_neuron):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_neuron,hidden1_neuron)\n",
    "        self.fc2 = nn.Linear(hidden1_neuron,hidden2_neuron)\n",
    "        self.fc3 = nn.Linear(hidden2_neuron,out_neuron)\n",
    "    def forward(self,x):\n",
    "        x = ReLu(self.fc1(x))\n",
    "        x = ReLu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_act = ThreeLayerFC_act(in_neuron,hidden1_neuron,hidden2_neuron,out_neuron)\n",
    "optimizer = optim.SGD(model_o_act.parameters(),lr) #default momentum=0\n",
    "epoch=100\n",
    "\n",
    "train_loss,val_loss = trainer(model_o_act,optimizer,epoch)\n",
    "loss_plot(train_loss,val_loss,epoch,\"loss_o_act\")\n",
    "PATH = os.path.join(os.path.abspath(\".\"), \"model\")\n",
    "torch.save(model_o_act,PATH)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
